{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from itertools import dropwhile\n",
    "import string\n",
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'theano'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers.recurrent import GRU\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers.core import Dense, RepeatVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
    "MODEL_PATH = 'models'\n",
    "\n",
    "MODEL_STRUCT_FILE = 'piglatin_struct.json'\n",
    "MODEL_WEIGHTS_FILE = 'piglatin_weights.h5'\n",
    "\n",
    "DATA_PATH = 'data'\n",
    "WORDS_FILE = 'words.txt'\n",
    "BEGIN_SYMBOL = '^'\n",
    "END_SYMBOL = '$'\n",
    "BLANK = ' '\n",
    "CHAR_SET = set(string.ascii_lowercase + BEGIN_SYMBOL + END_SYMBOL)\n",
    "CHAR_NUM = len(CHAR_SET)\n",
    "CHAR_TO_INDICES = {c:i for i, c in enumerate(CHAR_SET)}\n",
    "INDICES_TO_CHAR = {i:c for c, i in CHAR_TO_INDICES.iteritems()}\n",
    "MAX_INPUT_LEN = 18\n",
    "MAX_OUTPUT_LEN = 20\n",
    "NON_ALPHA_PAT = re.compile('[^a-z]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_vowel(char):\n",
    "    return char in ('a', 'e', 'i', 'o', 'u')\n",
    "\n",
    "\n",
    "def is_consonant(char):\n",
    "    return not is_vowel(char)\n",
    "\n",
    "\n",
    "def pig_latin(word):\n",
    "    if is_vowel(word[0]):\n",
    "        return word + 'yay'\n",
    "    else:\n",
    "        remain = ''.join(dropwhile(is_consonant, word))\n",
    "        removed = word[:len(word)-len(remain)]\n",
    "        return remain + removed + 'ay'\n",
    "\n",
    "\n",
    "def vectorize(word, seq_len, vec_size):\n",
    "    vec = np.zeros((seq_len, vec_size), dtype=int)\n",
    "    for i, ch in enumerate(word):\n",
    "        vec[i, CHAR_TO_INDICES[ch]] = 1\n",
    "\n",
    "    for i in range(len(word), seq_len):\n",
    "        vec[i, CHAR_TO_INDICES[END_SYMBOL]] = 1\n",
    "\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_data():\n",
    "    words_file = 'words.txt'#os.path.join(PROJECT_ROOT, DATA_PATH, WORDS_FILE)\n",
    "    words = [\n",
    "        w.lower().strip() for w in open(words_file, 'r').readlines()\n",
    "        if w.strip() != '' and not NON_ALPHA_PAT.findall(w.lower().strip())\n",
    "    ]\n",
    "\n",
    "    plain_x = []\n",
    "    plain_y = []\n",
    "    for w in words:\n",
    "        plain_x.append(BEGIN_SYMBOL + w)\n",
    "        plain_y.append(BEGIN_SYMBOL + pig_latin(w))\n",
    "\n",
    "    # train_x train_y\n",
    "    train_x = np.zeros((len(words), MAX_INPUT_LEN, CHAR_NUM), dtype=int)\n",
    "    train_y = np.zeros((len(words), MAX_OUTPUT_LEN, CHAR_NUM), dtype=int)\n",
    "    for i in range(len(words)):\n",
    "        train_x[i] = vectorize(plain_x[i], MAX_INPUT_LEN, CHAR_NUM)\n",
    "        train_y[i] = vectorize(plain_y[i], MAX_OUTPUT_LEN, CHAR_NUM)\n",
    "\n",
    "    return train_x, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207849, 18, 28)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x, y = build_data()\n",
    "indices = len(x) / 10\n",
    "test_x = x[:indices]\n",
    "test_y = y[:indices]\n",
    "train_x = x[indices:]\n",
    "train_y = y[indices:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((207849, 18, 28), 28)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, CHAR_NUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_model(input_size, seq_len, hidden_size):\n",
    "    \"\"\"sequence to sequence\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(GRU(input_dim=input_size, output_dim=hidden_size, return_sequences=False))\n",
    "    model.add(Dense(hidden_size, activation=\"relu\"))\n",
    "    model.add(RepeatVector(seq_len))\n",
    "    model.add(GRU(hidden_size, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(output_dim=input_size, activation=\"linear\")))\n",
    "    model.compile(loss=\"mse\", optimizer='adam')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "gru_3 (GRU)                      (None, 128)           60288       gru_input_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 128)           16512       gru_3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "repeatvector_2 (RepeatVector)    (None, 20, 128)       0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "gru_4 (GRU)                      (None, 20, 128)       98688       repeatvector_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_2 (TimeDistribut (None, 20, 28)        3612        gru_4[0][0]                      \n",
      "====================================================================================================\n",
      "Total params: 179100\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(CHAR_NUM, MAX_OUTPUT_LEN, 128)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 207849 samples, validate on 23094 samples\n",
      "Epoch 1/20\n",
      "207849/207849 [==============================] - 549s - loss: 0.0163 - val_loss: 0.0214\n",
      "Epoch 2/20\n",
      "207849/207849 [==============================] - 557s - loss: 0.0143 - val_loss: 0.0181\n",
      "Epoch 3/20\n",
      "207849/207849 [==============================] - 561s - loss: 0.0121 - val_loss: 0.0144\n",
      "Epoch 4/20\n",
      "207849/207849 [==============================] - 565s - loss: 0.0107 - val_loss: 0.0123\n",
      "Epoch 5/20\n",
      "207849/207849 [==============================] - 565s - loss: 0.0096 - val_loss: 0.0110\n",
      "Epoch 6/20\n",
      "207849/207849 [==============================] - 566s - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 7/20\n",
      "207849/207849 [==============================] - 564s - loss: 0.0080 - val_loss: 0.0092\n",
      "Epoch 8/20\n",
      "207849/207849 [==============================] - 561s - loss: 0.0071 - val_loss: 0.0075\n",
      "Epoch 9/20\n",
      "207849/207849 [==============================] - 560s - loss: 0.0071 - val_loss: 0.0068\n",
      "Epoch 10/20\n",
      "207849/207849 [==============================] - 560s - loss: 0.0068 - val_loss: 0.0064\n",
      "Epoch 11/20\n",
      "207849/207849 [==============================] - 555s - loss: 0.0055 - val_loss: 0.0061\n",
      "Epoch 12/20\n",
      "207849/207849 [==============================] - 558s - loss: 0.0048 - val_loss: 0.0056\n",
      "Epoch 13/20\n",
      "207849/207849 [==============================] - 555s - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 14/20\n",
      "207849/207849 [==============================] - 554s - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 15/20\n",
      "207849/207849 [==============================] - 554s - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 16/20\n",
      "207849/207849 [==============================] - 550s - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 17/20\n",
      "207849/207849 [==============================] - 555s - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 18/20\n",
      "207849/207849 [==============================] - 557s - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 19/20\n",
      "207849/207849 [==============================] - 557s - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 20/20\n",
      "207849/207849 [==============================] - 550s - loss: 0.0032 - val_loss: 0.0032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xaa8e47ec>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, validation_data=(test_x, test_y), batch_size=128, nb_epoch=20,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loaded_model.compile(loss=\"mse\", optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "say = 'hola'\n",
    "X = np.zeros((1,MAX_INPUT_LEN, CHAR_NUM), dtype=int)\n",
    "Word = BEGIN_SYMBOL + say.lower().strip() + END_SYMBOL\n",
    "X[0] = vectorize(Word, MAX_INPUT_LEN, CHAR_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = loaded_model.predict(X)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qqoooooooooooooooooo\n"
     ]
    }
   ],
   "source": [
    "print ''.join([\n",
    "        INDICES_TO_CHAR[i] for i in pred.argmax(axis=1)\n",
    "        if INDICES_TO_CHAR[i] not in (BEGIN_SYMBOL, END_SYMBOL)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h\n",
      "o\n",
      "l\n",
      "a\n"
     ]
    }
   ],
   "source": [
    "for i in X[0].argmax(axis=1):\n",
    "    if INDICES_TO_CHAR[i] not in (BEGIN_SYMBOL,END_SYMBOL):\n",
    "        print INDICES_TO_CHAR[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'exsay'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pig_latin('sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def translate_to_pig(say='helo'):\n",
    "    X = np.zeros((1,MAX_INPUT_LEN, CHAR_NUM), dtype=int)\n",
    "    Word = BEGIN_SYMBOL + say.lower().strip() + END_SYMBOL\n",
    "    X[0] = vectorize(Word, MAX_INPUT_LEN, CHAR_NUM)\n",
    "    pred = model.predict(X)[0]\n",
    "    print ''.join([\n",
    "        INDICES_TO_CHAR[i] for i in pred.argmax(axis=0)\n",
    "        if INDICES_TO_CHAR[i] not in (BEGIN_SYMBOL, END_SYMBOL)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slscksnmsmsefsh\n"
     ]
    }
   ],
   "source": [
    "translate_to_pig('sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
